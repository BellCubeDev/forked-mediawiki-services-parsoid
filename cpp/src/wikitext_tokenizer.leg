%{
#include <vector>
#include <iostream>
#include "parsoid_internal.hpp"
using namespace std;
using namespace parsoid;

// Actions are supposed to return this type as semantic value
#define YYSTYPE vector<Tk>

// local tokenizer context
#define YY_CTX_LOCAL

#define YY_INPUT(buf, result, max)  \
    { \
        result = 0; \
    }

// Add a reference to the driving WikiTokenizer object as an additional state
// member
#define YY_CTX_MEMBERS WikiTokenizer* tokenizer;

// Define a few convenience macros to make things more readable
#define emit ctx->tokenizer->emit
#define pushScope ctx->tokenizer->pushScope
#define popScope ctx->tokenizer->popScope
#define getAccum ctx->tokenizer->getAccum

#define incFlag ctx->tokenizer->syntaxFlags->inc
#define decFlag ctx->tokenizer->syntaxFlags->dec
#define pushFlag ctx->tokenizer->syntaxFlags->push
#define popFlag ctx->tokenizer->syntaxFlags->pop
#define getFlag ctx->tokenizer->syntaxFlags->get
             
%}


#/*********************************************************
# * The top-level production
# *********************************************************/
start = e:toplevelblock+ newline* { $$ = e; }

#
# A document (start production) is a sequence of toplevelblocks. Tokens are
# emitted in chunks per toplevelblock to avoid buffering the full document.
#
toplevelblock = block

# TODO: implement!
block = 
    newline? l:line
    { cout << "last block token: " << getAccum()->back().toString() << endl; }

#list = "*" text { 
#        vector<Token>* v = new vector<Token> { new StartTagTk('listitem') }; 
#        v.push_back( 
#    }

line = < [^\n] > { emit( mkText(yytext) ); }

#eof = & { false }

newline = '\n' | '\r\n'

#eolf = newline | eof

# TODO: use a stack of accumulators
# Need stack to support nesting (inline link content within link token for
# example), nested_block, nested_inlineline, nested_inline..
#
# * Start a new current accumulator, push old one on stack
# * In main action: pop & concat
StartChunk = &. { pushScope(); }
